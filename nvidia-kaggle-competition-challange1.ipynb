{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce3aec12",
   "metadata": {
    "papermill": {
     "duration": 0.004202,
     "end_time": "2025-04-06T20:07:13.869579",
     "exception": false,
     "start_time": "2025-04-06T20:07:13.865377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Title: Nvidia Kaggle Compition\n",
    "\n",
    "**Author : Jasmeen Sameer Shaikh**\n",
    "\n",
    "**Github : [Jasmeen Guithub ID](http://github.com/jass2422)**\n",
    "\n",
    "\n",
    "**LinkedIn:[Jasmeen LinkedIn ID](http://www.linkedin.com/in/jasmeen-shaikh-075b35240/)**\n",
    "\n",
    "\n",
    "\n",
    "**This code implements a Multi-Layer Perceptron (MLP) using PyTorch to classify handwritten digits from the MNIST dataset. MNIST is a well-known benchmark in machine learning, consisting of 70,000 grayscale images of digits from 0 to 9. The goal is to build a deep neural network that learns meaningful patterns from the training data and generalizes well to unseen test data. The model consists of fully connected layers with ReLU activations and Dropout for regularization. It is trained using the Adam optimizer and CrossEntropy loss, which are well-suited for multiclass classification tasks. With proper architecture and training, this MLP achieves over 95% test accuracy on MNIST.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5af2481",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:13.877986Z",
     "iopub.status.busy": "2025-04-06T20:07:13.877692Z",
     "iopub.status.idle": "2025-04-06T20:07:14.642776Z",
     "shell.execute_reply": "2025-04-06T20:07:14.641720Z"
    },
    "papermill": {
     "duration": 0.771412,
     "end_time": "2025-04-06T20:07:14.644573",
     "exception": false,
     "start_time": "2025-04-06T20:07:13.873161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bd70003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:14.653162Z",
     "iopub.status.busy": "2025-04-06T20:07:14.652694Z",
     "iopub.status.idle": "2025-04-06T20:07:23.013009Z",
     "shell.execute_reply": "2025-04-06T20:07:23.012259Z"
    },
    "papermill": {
     "duration": 8.366216,
     "end_time": "2025-04-06T20:07:23.014774",
     "exception": false,
     "start_time": "2025-04-06T20:07:14.648558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa5646",
   "metadata": {
    "papermill": {
     "duration": 0.003047,
     "end_time": "2025-04-06T20:07:23.021455",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.018408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a5aa8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:23.029086Z",
     "iopub.status.busy": "2025-04-06T20:07:23.028650Z",
     "iopub.status.idle": "2025-04-06T20:07:23.077591Z",
     "shell.execute_reply": "2025-04-06T20:07:23.076651Z"
    },
    "papermill": {
     "duration": 0.054411,
     "end_time": "2025-04-06T20:07:23.079079",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.024668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fde2fe",
   "metadata": {
    "papermill": {
     "duration": 0.003168,
     "end_time": "2025-04-06T20:07:23.085996",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.082828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8686bce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:23.093676Z",
     "iopub.status.busy": "2025-04-06T20:07:23.093366Z",
     "iopub.status.idle": "2025-04-06T20:07:23.097013Z",
     "shell.execute_reply": "2025-04-06T20:07:23.096323Z"
    },
    "papermill": {
     "duration": 0.008773,
     "end_time": "2025-04-06T20:07:23.098215",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.089442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_size = 28 * 28\n",
    "hidden_sizes = [512, 256]\n",
    "output_size = 10\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1a886",
   "metadata": {
    "papermill": {
     "duration": 0.003274,
     "end_time": "2025-04-06T20:07:23.105168",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.101894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d19046",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:23.113204Z",
     "iopub.status.busy": "2025-04-06T20:07:23.112850Z",
     "iopub.status.idle": "2025-04-06T20:07:28.158054Z",
     "shell.execute_reply": "2025-04-06T20:07:28.156976Z"
    },
    "papermill": {
     "duration": 5.050965,
     "end_time": "2025-04-06T20:07:28.159777",
     "exception": false,
     "start_time": "2025-04-06T20:07:23.108812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 12.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 340kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.64MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec0851",
   "metadata": {
    "papermill": {
     "duration": 0.006182,
     "end_time": "2025-04-06T20:07:28.171638",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.165456",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define the MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d11e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:28.182687Z",
     "iopub.status.busy": "2025-04-06T20:07:28.182323Z",
     "iopub.status.idle": "2025-04-06T20:07:28.377106Z",
     "shell.execute_reply": "2025-04-06T20:07:28.376105Z"
    },
    "papermill": {
     "duration": 0.202214,
     "end_time": "2025-04-06T20:07:28.378876",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.176662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.dropout1(self.relu1(self.fc1(x)))\n",
    "        x = self.dropout2(self.relu2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = MLP().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9527591",
   "metadata": {
    "papermill": {
     "duration": 0.006383,
     "end_time": "2025-04-06T20:07:28.390694",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.384311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c08e718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:28.402392Z",
     "iopub.status.busy": "2025-04-06T20:07:28.402042Z",
     "iopub.status.idle": "2025-04-06T20:07:28.406229Z",
     "shell.execute_reply": "2025-04-06T20:07:28.405332Z"
    },
    "papermill": {
     "duration": 0.011428,
     "end_time": "2025-04-06T20:07:28.407564",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.396136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26bc4e",
   "metadata": {
    "papermill": {
     "duration": 0.004704,
     "end_time": "2025-04-06T20:07:28.417162",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.412458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5924dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:07:28.427436Z",
     "iopub.status.busy": "2025-04-06T20:07:28.427156Z",
     "iopub.status.idle": "2025-04-06T20:09:49.809801Z",
     "shell.execute_reply": "2025-04-06T20:09:49.808811Z"
    },
    "papermill": {
     "duration": 141.389692,
     "end_time": "2025-04-06T20:09:49.811502",
     "exception": false,
     "start_time": "2025-04-06T20:07:28.421810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2377\n",
      "Epoch [2/10], Loss: 0.1151\n",
      "Epoch [3/10], Loss: 0.0838\n",
      "Epoch [4/10], Loss: 0.0738\n",
      "Epoch [5/10], Loss: 0.0612\n",
      "Epoch [6/10], Loss: 0.0567\n",
      "Epoch [7/10], Loss: 0.0525\n",
      "Epoch [8/10], Loss: 0.0455\n",
      "Epoch [9/10], Loss: 0.0450\n",
      "Epoch [10/10], Loss: 0.0433\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9ec1a6",
   "metadata": {
    "papermill": {
     "duration": 0.00516,
     "end_time": "2025-04-06T20:09:49.821886",
     "exception": false,
     "start_time": "2025-04-06T20:09:49.816726",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162a40db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-06T20:09:49.834256Z",
     "iopub.status.busy": "2025-04-06T20:09:49.833964Z",
     "iopub.status.idle": "2025-04-06T20:09:51.880254Z",
     "shell.execute_reply": "2025-04-06T20:09:51.879300Z"
    },
    "papermill": {
     "duration": 2.054552,
     "end_time": "2025-04-06T20:09:51.881682",
     "exception": false,
     "start_time": "2025-04-06T20:09:49.827130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.90%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae10aab",
   "metadata": {
    "papermill": {
     "duration": 0.00528,
     "end_time": "2025-04-06T20:09:51.892509",
     "exception": false,
     "start_time": "2025-04-06T20:09:51.887229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "**In this project, we successfully developed a neural network using PyTorch that achieves high accuracy in digit classification on the MNIST dataset. Through the use of a well-structured MLP architecture, effective regularization (Dropout), and optimization techniques (Adam), the model reaches a test accuracy of over 97%. This performance demonstrates that even a relatively simple MLP, when properly tuned, can deliver robust results on image classification tasks. The approach can serve as a strong baseline for more complex models like CNNs or hybrid architectures in computer vision problems.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbafbf7d",
   "metadata": {
    "papermill": {
     "duration": 0.005013,
     "end_time": "2025-04-06T20:09:51.903002",
     "exception": false,
     "start_time": "2025-04-06T20:09:51.897989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 861823,
     "sourceId": 3004,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 162.271048,
   "end_time": "2025-04-06T20:09:53.329062",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-06T20:07:11.058014",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
